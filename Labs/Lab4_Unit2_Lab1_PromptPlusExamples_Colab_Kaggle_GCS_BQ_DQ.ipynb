{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJNAha9YXamp"
      },
      "source": [
        "# MGMT 467 — Prompt-Driven Lab (with Commented Examples)\n",
        "## Kaggle ➜ Google Cloud Storage ➜ BigQuery ➜ Data Quality (DQ)\n",
        "\n",
        "**How to use this notebook**\n",
        "- Each section gives you a **Build Prompt** to paste into Gemini/Vertex AI (or Gemini in Colab).\n",
        "- Below each prompt, you’ll see a **commented example** of what a good LLM answer might look like.\n",
        "- **Do not** just uncomment and run. Use the prompt to generate your own code, then compare to the example.\n",
        "- After every step, run the **Verification Prompt**, and write the **Reflection** in Markdown.\n",
        "\n",
        "> Goal today: Download the Netflix dataset (Kaggle) → Stage on GCS → Load into BigQuery → Run DQ profiling (missingness, duplicates, outliers, anomaly flags).\n"
      ],
      "id": "PJNAha9YXamp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZhysU4YXamu"
      },
      "source": [
        "### Academic integrity & LLM usage\n",
        "- Use the prompts here to generate your own code cells.\n",
        "- Read concept notes and write the reflection answers in your own words.\n",
        "- Keep credentials out of code. Upload `kaggle.json` when asked.\n"
      ],
      "id": "HZhysU4YXamu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyjYSghdXamu"
      },
      "source": [
        "## Learning objectives\n",
        "1) Explain **why** we stage data in GCS and load it to BigQuery.  \n",
        "2) Build an **idempotent**, auditable pipeline.  \n",
        "3) Diagnose **missingness**, **duplicates**, and **outliers** and justify cleaning choices.  \n",
        "4) Connect DQ decisions to **business/ML impact**.\n"
      ],
      "id": "gyjYSghdXamu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSK-9hD_Xamw"
      },
      "source": [
        "## 0) Environment setup — What & Why\n",
        "Authenticate Colab to Google Cloud so we can use `gcloud`, GCS, and BigQuery. Set **PROJECT_ID** and **REGION** once for consistency (cost/latency)."
      ],
      "id": "HSK-9hD_Xamw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0wexPdXXamw"
      },
      "source": [
        "### Build Prompt (paste to LLM)\n",
        "You are my cloud TA. Generate a single **Colab code cell** that:\n",
        "1) Authenticates to Google Cloud in Colab,  \n",
        "2) Prompts for `PROJECT_ID` via `input()` and sets `REGION=\"us-central1\"` (editable),  \n",
        "3) Exports `GOOGLE_CLOUD_PROJECT`,  \n",
        "4) Runs `gcloud config set project $GOOGLE_CLOUD_PROJECT`,  \n",
        "5) Prints both values. Add 2–3 comments explaining what/why.\n",
        "End with a comment: `# Done: Auth + Project/Region set`.\n"
      ],
      "id": "B0wexPdXXamw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7c3c28e",
        "outputId": "94512cdc-729e-4c92-a681-f1c5b6313400"
      },
      "source": [
        "# Authenticate to Google Cloud in Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Prompt for PROJECT_ID and set REGION\n",
        "import os\n",
        "PROJECT_ID = input(\"Enter your GCP Project ID: \").strip()\n",
        "REGION = \"us-central1\"  # keep consistent; change if instructed\n",
        "\n",
        "# Export GOOGLE_CLOUD_PROJECT and REGION environment variables\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
        "os.environ[\"REGION\"] = REGION # Export REGION as an environment variable\n",
        "\n",
        "# Set active project for gcloud/BigQuery CLI\n",
        "!gcloud config set project $GOOGLE_CLOUD_PROJECT\n",
        "\n",
        "# Print the values\n",
        "print(\"Project:\", PROJECT_ID, \"| Region:\", REGION)\n",
        "\n",
        "# Done: Auth + Project/Region set"
      ],
      "id": "f7c3c28e",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your GCP Project ID: heroic-trilogy-471119-k8\n",
            "Updated property [core/project].\n",
            "Project: heroic-trilogy-471119-k8 | Region: us-central1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM-Ddpt3Xamx"
      },
      "execution_count": 2,
      "outputs": [],
      "source": [
        "# # EXAMPLE (from LLM) — Auth + Project/Region (commented; write your own cell using the prompt)\n",
        "# # from google.colab import auth\n",
        "# # auth.authenticate_user()\n",
        "# #\n",
        "# # import os\n",
        "# # PROJECT_ID = input(\"Enter your GCP Project ID: \").strip()\n",
        "# # REGION = \"us-central1\"  # keep consistent; change if instructed\n",
        "# # os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
        "# # print(\"Project:\", PROJECT_ID, \"| Region:\", REGION)\n",
        "# #\n",
        "# # # Set active project for gcloud/BigQuery CLI\n",
        "# # !gcloud config set project $GOOGLE_CLOUD_PROJECT\n",
        "# # !gcloud config get-value project\n",
        "# # # Done: Auth + Project/Region set"
      ],
      "id": "vM-Ddpt3Xamx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeynmNj-Xamy"
      },
      "source": [
        "### Verification Prompt\n",
        "Generate a short cell that prints the active project using `gcloud config get-value project` and echoes the `REGION` you set.\n"
      ],
      "id": "WeynmNj-Xamy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de4f147c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6c10397-d367-469a-ad19-d2bd075777d1"
      },
      "source": [
        "# Verify the active project and region\n",
        "# This confirms that the environment variables and gcloud configuration are set correctly.\n",
        "import os\n",
        "gcloud_project = !gcloud config get-value project\n",
        "print(\"Active gcloud project:\", gcloud_project[0])\n",
        "print(\"REGION:\", os.environ.get(\"REGION\", \"REGION environment variable not set\"))"
      ],
      "id": "de4f147c",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Active gcloud project: heroic-trilogy-471119-k8\n",
            "REGION: us-central1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y21BtfjXamz"
      },
      "source": [
        "**Reflection:** Why do we set `PROJECT_ID` and `REGION` at the top? What can go wrong if we don’t?\n",
        "\n",
        "We set the 'PROJECT_ID' and 'REGION' at the top to ensure consistency, reproducibility and cost and resource management. This ensures that when creating new commands, we are using the same project and region and anyone running the notebook can see which project and region are being used. It also helps manage operational cost within google cloud.\n",
        "\n",
        "If we don't set the 'PROJECT_ID' and 'REGION' at the top, then a lot of things can go wrong. For example, commands might fail because they do not know which project to operate in, datasets or buckets can be created in unexpected or default projects, making them difficult to manage. Then, costs could be incurred in different projects or regions, and reproducibility is compromised which can cause more errors."
      ],
      "id": "1Y21BtfjXamz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibzWlBFhXamz"
      },
      "source": [
        "## 1) Kaggle API — What & Why\n",
        "Use Kaggle CLI for reproducible downloads. Store `kaggle.json` at `~/.kaggle/kaggle.json` with `0600` permissions to protect secrets."
      ],
      "id": "ibzWlBFhXamz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaLijSXFXamz"
      },
      "source": [
        "### Build Prompt\n",
        "Generate a **single Colab code cell** that:\n",
        "- Prompts me to upload `kaggle.json`,\n",
        "- Saves to `~/.kaggle/kaggle.json` with `0600` permissions,\n",
        "- Prints `kaggle --version`.\n",
        "Add comments about security and reproducibility.\n"
      ],
      "id": "RaLijSXFXamz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17d43a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "3e98f906-004c-4be0-b2db-5093e7fa4c28"
      },
      "source": [
        "# Prompt to upload kaggle.json for Kaggle API authentication\n",
        "# This file contains your API credentials and should be kept secure.\n",
        "from google.colab import files\n",
        "print(\"Upload your kaggle.json (Kaggle > Account > Create New API Token)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Save kaggle.json to the correct directory with secure permissions\n",
        "# This ensures only the owner can read and write the file, protecting your credentials.\n",
        "import os\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "with open('/root/.kaggle/kaggle.json', 'wb') as f:\n",
        "    f.write(uploaded[list(uploaded.keys())[0]])\n",
        "os.chmod('/root/.kaggle/kaggle.json', 0o600)  # Set owner-only permissions\n",
        "\n",
        "# Verify the Kaggle CLI is installed and ready to use\n",
        "# This confirms the setup was successful and you can proceed with Kaggle commands.\n",
        "!kaggle --version"
      ],
      "id": "17d43a70",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your kaggle.json (Kaggle > Account > Create New API Token)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1cf46315-bf7d-4680-b245-89b446881bac\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1cf46315-bf7d-4680-b245-89b446881bac\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Kaggle API 1.7.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZNMZT1eXam0"
      },
      "execution_count": 5,
      "outputs": [],
      "source": [
        "# # EXAMPLE (from LLM) — Kaggle setup (commented)\n",
        "# # from google.colab import files\n",
        "# # print(\"Upload your kaggle.json (Kaggle > Account > Create New API Token)\")\n",
        "# # uploaded = files.upload()\n",
        "# #\n",
        "# # import os\n",
        "# # os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "# # with open('/root/.kaggle/kaggle.json', 'wb') as f:\n",
        "# #     f.write(uploaded[list(uploaded.keys())[0]])\n",
        "# # os.chmod('/root/.kaggle/kaggle.json', 0o600)  # owner-only\n",
        "# #\n",
        "# # !kaggle --version"
      ],
      "id": "5ZNMZT1eXam0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZZzIN27Xam0"
      },
      "source": [
        "### Verification Prompt\n",
        "Generate a one-liner that runs `kaggle --help | head -n 20` to show the CLI is ready.\n"
      ],
      "id": "CZZzIN27Xam0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "266de90f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc2b66b6-0984-4d00-db36-af819803456d"
      },
      "source": [
        "# Verify the Kaggle CLI is ready by showing the first 20 lines of the help output\n",
        "!kaggle --help | head -n 20"
      ],
      "id": "266de90f",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: kaggle [-h] [-v] [-W]\n",
            "              {competitions,c,datasets,d,kernels,k,models,m,files,f,config}\n",
            "              ...\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  -v, --version         Print the Kaggle API version\n",
            "  -W, --no-warn         Disable out-of-date API version warning\n",
            "\n",
            "commands:\n",
            "  {competitions,c,datasets,d,kernels,k,models,m,files,f,config}\n",
            "                        Use one of:\n",
            "                        competitions {list, files, download, submit, submissions, leaderboard}\n",
            "                        datasets {list, files, download, create, version, init, metadata, status}\n",
            "                        kernels {list, files, init, push, pull, output, status}\n",
            "                        models {instances, get, list, init, create, delete, update}\n",
            "                        models instances {versions, get, files, init, create, delete, update}\n",
            "                        models instances versions {init, create, download, delete, files}\n",
            "                        config {view, set, unset}\n",
            "    competitions (c)    Commands related to Kaggle competitions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XW6oxzGUXam0"
      },
      "source": [
        "**Reflection:** Why require strict `0600` permissions on API tokens? What risks are we avoiding?\n",
        "\n",
        "Requiring strict '0600' permissions on API tokens such as the 'kaggle.json' file ensures that only the owner of the file can read or write to it, thereby protecting the user's API token from being accessed by unintended parties. This is a crucial security measure that helps prevent unauthorized access to your credentials. The risks that we are avoiding are unauthorized access to the user's kaggle account, data breaches and malicious activity."
      ],
      "id": "XW6oxzGUXam0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1N8tFi3Xam0"
      },
      "source": [
        "## 2) Download & unzip dataset — What & Why\n",
        "Keep raw files under `/content/data/raw` for predictable paths and auditing.\n",
        "**Dataset:** `sayeeduddin/netflix-2025user-behavior-dataset-210k-records`"
      ],
      "id": "f1N8tFi3Xam0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTBPcHQcXam0"
      },
      "source": [
        "### Build Prompt\n",
        "Generate a **Colab code cell** that:\n",
        "- Creates `/content/data/raw`,\n",
        "- Downloads the dataset to `/content/data` with Kaggle CLI,\n",
        "- Unzips into `/content/data/raw` (overwrite OK),\n",
        "- Lists all CSVs with sizes in a neat table.\n",
        "Include comments describing each step.\n"
      ],
      "id": "NTBPcHQcXam0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c80454a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c138019d-4a28-46fb-871f-6227c37a5c1f"
      },
      "source": [
        "# Create directory for raw data\n",
        "# This ensures a clean and predictable location for the downloaded files.\n",
        "!mkdir -p /content/data/raw\n",
        "\n",
        "# Download the dataset from Kaggle to /content/data\n",
        "# Using the Kaggle CLI allows for reproducible downloads of datasets.\n",
        "!kaggle datasets download -d sayeeduddin/netflix-2025user-behavior-dataset-210k-records -p /content/data\n",
        "\n",
        "# Unzip the downloaded dataset into the raw data directory\n",
        "# The -o flag allows overwriting if the file already exists.\n",
        "!unzip -o /content/data/*.zip -d /content/data/raw\n",
        "\n",
        "# List all CSV files in the raw data directory with their sizes\n",
        "# This provides a quick inventory of the downloaded files.\n",
        "!ls -lh /content/data/raw/*.csv"
      ],
      "id": "c80454a9",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/sayeeduddin/netflix-2025user-behavior-dataset-210k-records\n",
            "License(s): CC0-1.0\n",
            "Downloading netflix-2025user-behavior-dataset-210k-records.zip to /content/data\n",
            "  0% 0.00/4.02M [00:00<?, ?B/s]\n",
            "100% 4.02M/4.02M [00:00<00:00, 564MB/s]\n",
            "Archive:  /content/data/netflix-2025user-behavior-dataset-210k-records.zip\n",
            "  inflating: /content/data/raw/README.md  \n",
            "  inflating: /content/data/raw/movies.csv  \n",
            "  inflating: /content/data/raw/recommendation_logs.csv  \n",
            "  inflating: /content/data/raw/reviews.csv  \n",
            "  inflating: /content/data/raw/search_logs.csv  \n",
            "  inflating: /content/data/raw/users.csv  \n",
            "  inflating: /content/data/raw/watch_history.csv  \n",
            "-rw-r--r-- 1 root root 114K Aug  2 19:36 /content/data/raw/movies.csv\n",
            "-rw-r--r-- 1 root root 4.5M Aug  2 19:36 /content/data/raw/recommendation_logs.csv\n",
            "-rw-r--r-- 1 root root 1.8M Aug  2 19:36 /content/data/raw/reviews.csv\n",
            "-rw-r--r-- 1 root root 2.2M Aug  2 19:36 /content/data/raw/search_logs.csv\n",
            "-rw-r--r-- 1 root root 1.6M Aug  2 19:36 /content/data/raw/users.csv\n",
            "-rw-r--r-- 1 root root 8.9M Aug  2 19:36 /content/data/raw/watch_history.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0fVsxJnXam0"
      },
      "execution_count": 9,
      "outputs": [],
      "source": [
        "# # EXAMPLE (from LLM) — Download & unzip (commented)\n",
        "# # !mkdir -p /content/data/raw\n",
        "# # !kaggle datasets download -d sayeeduddin/netflix-2025user-behavior-dataset-210k-records -p /content/data\n",
        "# # !unzip -o /content/data/*.zip -d /content/data/raw\n",
        "# # # List CSV inventory\n",
        "# # !ls -lh /content/data/raw/*.csv"
      ],
      "id": "H0fVsxJnXam0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQcvhM7LXam0"
      },
      "source": [
        "### Verification Prompt\n",
        "Generate a snippet that asserts there are exactly **six** CSV files and prints their names.\n"
      ],
      "id": "wQcvhM7LXam0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87975b9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22d13555-e31f-4492-e460-53f414a2fb4a"
      },
      "source": [
        "# Verify there are exactly six CSV files and print their names\n",
        "import glob\n",
        "csv_files = glob.glob('/content/data/raw/*.csv')\n",
        "num_csv_files = len(csv_files)\n",
        "\n",
        "print(f\"Found {num_csv_files} CSV files.\")\n",
        "\n",
        "if num_csv_files == 6:\n",
        "    print(\"Verification successful: Exactly 6 CSV files found.\")\n",
        "    print(\"CSV files:\")\n",
        "    for csv_file in csv_files:\n",
        "        print(csv_file)\n",
        "else:\n",
        "    print(\"Verification failed: Expected 6 CSV files, but found\", num_csv_files)"
      ],
      "id": "87975b9a",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6 CSV files.\n",
            "Verification successful: Exactly 6 CSV files found.\n",
            "CSV files:\n",
            "/content/data/raw/movies.csv\n",
            "/content/data/raw/reviews.csv\n",
            "/content/data/raw/users.csv\n",
            "/content/data/raw/recommendation_logs.csv\n",
            "/content/data/raw/search_logs.csv\n",
            "/content/data/raw/watch_history.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1lEtQKdXam0"
      },
      "source": [
        "**Reflection:** Why is keeping a clean file inventory (names, sizes) useful downstream?\n",
        "\n",
        "Keeping a clean file inventory provides a foundational layer of transparency and control over your data inputs, which is essential for building reliable and maintainable data pipelines. It is useful for several reasons such as auditing and reproducibility, troubleshooting, data integrity checks, documentation and input for automation.\n",
        "\n"
      ],
      "id": "J1lEtQKdXam0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPYyzL6jXam0"
      },
      "source": [
        "## 3) Create GCS bucket & upload — What & Why\n",
        "Stage in GCS → consistent, versionable source for BigQuery loads. Bucket names must be **globally unique**."
      ],
      "id": "gPYyzL6jXam0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNxrWp4GXam1"
      },
      "source": [
        "### Build Prompt\n",
        "Generate a **Colab code cell** that:\n",
        "- Creates a unique bucket in `${REGION}` (random suffix),\n",
        "- Saves name to `BUCKET_NAME` env var,\n",
        "- Uploads all CSVs to `gs://$BUCKET_NAME/netflix/`,\n",
        "- Prints the bucket name and explains staging benefits.\n"
      ],
      "id": "YNxrWp4GXam1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1157be03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2b19e4e-16fc-4999-843d-35f982e6d40a"
      },
      "source": [
        "# Create a unique bucket name with a random suffix\n",
        "import uuid\n",
        "import os\n",
        "\n",
        "# Ensure REGION is set in the Python environment\n",
        "REGION = os.environ.get(\"REGION\", \"us-central1\") # Get from env or default if not set\n",
        "os.environ[\"REGION\"] = REGION # Ensure it's set for subsequent Python calls\n",
        "\n",
        "bucket_name = f\"mgmt467-netflix-{uuid.uuid4().hex[:8]}\"\n",
        "\n",
        "# Save the bucket name to an environment variable\n",
        "os.environ[\"BUCKET_NAME\"] = bucket_name\n",
        "\n",
        "# Create the GCS bucket in the specified region\n",
        "# The --location flag ensures the bucket is created in the desired region.\n",
        "# The command will succeed even if the bucket name was somehow already taken (though unlikely with uuid).\n",
        "print(f\"Attempting to create bucket {bucket_name} in region {os.environ['REGION']}\")\n",
        "!gcloud storage buckets create gs://$BUCKET_NAME --location=$REGION\n",
        "\n",
        "# Upload all CSV files from the raw data directory to the bucket under a 'netflix/' prefix\n",
        "# Staging data in GCS provides a durable, versionable, and accessible source for cloud services like BigQuery.\n",
        "print(f\"Uploading files to gs://{bucket_name}/netflix/\")\n",
        "!gcloud storage cp /content/data/raw/*.csv gs://$BUCKET_NAME/netflix/\n",
        "\n",
        "# Print the created bucket name\n",
        "print(\"\\nCreated GCS bucket:\", bucket_name)\n",
        "print(\"\\nBenefits of staging data in GCS:\")\n",
        "print(\"- **Durability:** Data is stored redundantly across multiple devices and locations.\")\n",
        "print(\"- **Accessibility:** Data can be easily accessed by various Google Cloud services (BigQuery, Dataflow, AI Platform, etc.).\")\n",
        "print(\"- **Versionability:** GCS supports object versioning, allowing you to retrieve previous versions of your data.\")\n",
        "print(\"- **Scalability:** GCS can handle virtually unlimited amounts of data.\")"
      ],
      "id": "1157be03",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to create bucket mgmt467-netflix-26c8777a in region us-central1\n",
            "Creating gs://mgmt467-netflix-26c8777a/...\n",
            "Uploading files to gs://mgmt467-netflix-26c8777a/netflix/\n",
            "Copying file:///content/data/raw/movies.csv to gs://mgmt467-netflix-26c8777a/netflix/movies.csv\n",
            "Copying file:///content/data/raw/recommendation_logs.csv to gs://mgmt467-netflix-26c8777a/netflix/recommendation_logs.csv\n",
            "Copying file:///content/data/raw/reviews.csv to gs://mgmt467-netflix-26c8777a/netflix/reviews.csv\n",
            "Copying file:///content/data/raw/search_logs.csv to gs://mgmt467-netflix-26c8777a/netflix/search_logs.csv\n",
            "Copying file:///content/data/raw/users.csv to gs://mgmt467-netflix-26c8777a/netflix/users.csv\n",
            "Copying file:///content/data/raw/watch_history.csv to gs://mgmt467-netflix-26c8777a/netflix/watch_history.csv\n",
            "\n",
            "Average throughput: 11.0MiB/s\n",
            "\n",
            "Created GCS bucket: mgmt467-netflix-26c8777a\n",
            "\n",
            "Benefits of staging data in GCS:\n",
            "- **Durability:** Data is stored redundantly across multiple devices and locations.\n",
            "- **Accessibility:** Data can be easily accessed by various Google Cloud services (BigQuery, Dataflow, AI Platform, etc.).\n",
            "- **Versionability:** GCS supports object versioning, allowing you to retrieve previous versions of your data.\n",
            "- **Scalability:** GCS can handle virtually unlimited amounts of data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E3mfTvrXam1"
      },
      "execution_count": 12,
      "outputs": [],
      "source": [
        "# # EXAMPLE (from LLM) — GCS staging (commented)\n",
        "# # import uuid, os\n",
        "# # bucket_name = f\"mgmt467-netflix-{uuid.uuid4().hex[:8]}\"\n",
        "# # os.environ[\"BUCKET_NAME\"] = bucket_name\n",
        "# # !gcloud storage buckets create gs://$BUCKET_NAME --location=$REGION\n",
        "# # !gcloud storage cp /content/data/raw/* gs://$BUCKET_NAME/netflix/\n",
        "# # print(\"Bucket:\", bucket_name)\n",
        "# # # Verify contents\n",
        "# # !gcloud storage ls gs://$BUCKET_NAME/netflix/"
      ],
      "id": "8E3mfTvrXam1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EHOmyJeXam1"
      },
      "source": [
        "### Verification Prompt\n",
        "Generate a snippet that lists the `netflix/` prefix and shows object sizes.\n"
      ],
      "id": "8EHOmyJeXam1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f79aa991",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "164b9a4e-5aee-4341-f574-7ab03a6694fb"
      },
      "source": [
        "# List objects in the bucket under the 'netflix/' prefix and show details (including size)\n",
        "import os\n",
        "bucket_name = os.environ.get(\"BUCKET_NAME\")\n",
        "if bucket_name:\n",
        "  !gcloud storage ls -l gs://$BUCKET_NAME/netflix/\n",
        "else:\n",
        "  print(\"BUCKET_NAME environment variable is not set.\")"
      ],
      "id": "f79aa991",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    115942  2025-10-21T03:35:02Z  gs://mgmt467-netflix-26c8777a/netflix/movies.csv\n",
            "   4695557  2025-10-21T03:35:03Z  gs://mgmt467-netflix-26c8777a/netflix/recommendation_logs.csv\n",
            "   1861942  2025-10-21T03:35:03Z  gs://mgmt467-netflix-26c8777a/netflix/reviews.csv\n",
            "   2250902  2025-10-21T03:35:03Z  gs://mgmt467-netflix-26c8777a/netflix/search_logs.csv\n",
            "   1606820  2025-10-21T03:35:03Z  gs://mgmt467-netflix-26c8777a/netflix/users.csv\n",
            "   9269425  2025-10-21T03:35:04Z  gs://mgmt467-netflix-26c8777a/netflix/watch_history.csv\n",
            "TOTAL: 6 objects, 19800588 bytes (18.88MiB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnOdITYsXam1"
      },
      "source": [
        "**Reflection:** Name two benefits of staging in GCS vs loading directly from local Colab.\n",
        "\n",
        "The two benefits of staging in GCS vs loading directly from local Colab are scalability and accessibility and durability and reliability. That is to say, GCS provides a more robust, scalable, and integrated platform for managing and processing your data within the Google Cloud ecosystem."
      ],
      "id": "rnOdITYsXam1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T81K3_vcXam1"
      },
      "source": [
        "## 4) BigQuery dataset & loads — What & Why\n",
        "Create dataset `netflix` and load six CSVs with **autodetect** for speed (we’ll enforce schemas later)."
      ],
      "id": "T81K3_vcXam1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNSuL7RBXam1"
      },
      "source": [
        "### Build Prompt (two cells)\n",
        "**Cell A:** Create (idempotently) dataset `netflix` in US multi-region; if it exists, print a friendly message.  \n",
        "**Cell B:** Load tables from `gs://$BUCKET_NAME/netflix/`:\n",
        "`users, movies, watch_history, recommendation_logs, search_logs, reviews`\n",
        "with `--skip_leading_rows=1 --autodetect --source_format=CSV`.\n",
        "Finish with row-count queries for each table.\n"
      ],
      "id": "LNSuL7RBXam1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "768ce3b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbda6a1d-de23-47a6-fcb7-45a2bd053861"
      },
      "source": [
        "# Cell A: Create BigQuery dataset (idempotent)\n",
        "DATASET=\"netflix\"\n",
        "# Attempt to create; ignore if exists and print a message\n",
        "!bq --location=US mk -d --description \"MGMT467 Netflix dataset\" $DATASET 2> /dev/null || echo \"BigQuery dataset '$DATASET' may already exist.\""
      ],
      "id": "768ce3b7",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BigQuery error in mk operation: Dataset 'heroic-trilogy-471119-k8:netflix'\n",
            "already exists.\n",
            "BigQuery dataset '' may already exist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8be4a2c",
        "outputId": "dbf0b55b-6be2-40e4-eb0d-f8ce76b62375"
      },
      "source": [
        "# Load tables from GCS and get row counts\n",
        "tables = {\n",
        "  \"users\": \"users.csv\",\n",
        "  \"movies\": \"movies.csv\",\n",
        "  \"watch_history\": \"watch_history.csv\",\n",
        "  \"recommendation_logs\": \"recommendation_logs.csv\",\n",
        "  \"search_logs\": \"search_logs.csv\",\n",
        "  \"reviews\": \"reviews.csv\",\n",
        "}\n",
        "\n",
        "import os\n",
        "project_id = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
        "bucket_name = os.environ.get(\"BUCKET_NAME\")\n",
        "dataset = \"netflix\" # Ensure dataset name is consistent\n",
        "\n",
        "if not project_id:\n",
        "    print(\"Error: GOOGLE_CLOUD_PROJECT environment variable is not set.\")\n",
        "elif not bucket_name:\n",
        "    print(\"Error: BUCKET_NAME environment variable is not set.\")\n",
        "else:\n",
        "    for tbl, fname in tables.items():\n",
        "      src = f\"gs://{bucket_name}/netflix/{fname}\"\n",
        "      print(f\"Loading {dataset}.{tbl} from {src}\")\n",
        "      # Use --replace to make the load idempotent\n",
        "      !bq load --location=US --skip_leading_rows=1 --autodetect --source_format=CSV --replace {dataset}.{tbl} {src}\n",
        "\n",
        "    # Row counts for verification\n",
        "    for tbl in tables.keys():\n",
        "      !bq query --nouse_legacy_sql \"SELECT '{tbl}' AS table_name, COUNT(*) AS n FROM `${GOOGLE_CLOUD_PROJECT}.netflix.{tbl}`\".format(tbl=tbl)"
      ],
      "id": "e8be4a2c",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading netflix.users from gs://mgmt467-netflix-26c8777a/netflix/users.csv\n",
            "Waiting on bqjob_r79fa71091257974c_0000019a05027004_1 ... (1s) Current status: DONE   \n",
            "Loading netflix.movies from gs://mgmt467-netflix-26c8777a/netflix/movies.csv\n",
            "Waiting on bqjob_r2c245e5c599837ff_0000019a05028df8_1 ... (1s) Current status: DONE   \n",
            "Loading netflix.watch_history from gs://mgmt467-netflix-26c8777a/netflix/watch_history.csv\n",
            "Waiting on bqjob_r52761e7f62b060d0_0000019a0502abc9_1 ... (2s) Current status: DONE   \n",
            "Loading netflix.recommendation_logs from gs://mgmt467-netflix-26c8777a/netflix/recommendation_logs.csv\n",
            "Waiting on bqjob_r21c4f8318d3fbd2d_0000019a0502d037_1 ... (1s) Current status: DONE   \n",
            "Loading netflix.search_logs from gs://mgmt467-netflix-26c8777a/netflix/search_logs.csv\n",
            "Waiting on bqjob_r6ce5994141fc3c71_0000019a0502eda0_1 ... (1s) Current status: DONE   \n",
            "Loading netflix.reviews from gs://mgmt467-netflix-26c8777a/netflix/reviews.csv\n",
            "Waiting on bqjob_r44dccb54fec05ce_0000019a05030b91_1 ... (1s) Current status: DONE   \n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `bq query --nouse_legacy_sql \"SELECT '{tbl}' AS table_name, COUNT(*) AS n FROM `${GOOGLE_CLOUD_PROJECT}.netflix.{tbl}`\".format(tbl=tbl)'\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `bq query --nouse_legacy_sql \"SELECT '{tbl}' AS table_name, COUNT(*) AS n FROM `${GOOGLE_CLOUD_PROJECT}.netflix.{tbl}`\".format(tbl=tbl)'\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `bq query --nouse_legacy_sql \"SELECT '{tbl}' AS table_name, COUNT(*) AS n FROM `${GOOGLE_CLOUD_PROJECT}.netflix.{tbl}`\".format(tbl=tbl)'\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `bq query --nouse_legacy_sql \"SELECT '{tbl}' AS table_name, COUNT(*) AS n FROM `${GOOGLE_CLOUD_PROJECT}.netflix.{tbl}`\".format(tbl=tbl)'\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `bq query --nouse_legacy_sql \"SELECT '{tbl}' AS table_name, COUNT(*) AS n FROM `${GOOGLE_CLOUD_PROJECT}.netflix.{tbl}`\".format(tbl=tbl)'\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `bq query --nouse_legacy_sql \"SELECT '{tbl}' AS table_name, COUNT(*) AS n FROM `${GOOGLE_CLOUD_PROJECT}.netflix.{tbl}`\".format(tbl=tbl)'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** I don't know why the code above does not give the row_counts. But, it does load the datasets. Gemini re-generated this code several times, yet no progress. My code also looks similar to the ones below, commented section but still it does not seem to work. I struggled with making this work during class lab too.  "
      ],
      "metadata": {
        "id": "OKH2oHnUA2qg"
      },
      "id": "OKH2oHnUA2qg"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMuyJGutXam1"
      },
      "execution_count": 34,
      "outputs": [],
      "source": [
        "# # EXAMPLE (from LLM) — BigQuery dataset (commented)\n",
        "# # DATASET=\"netflix\"\n",
        "# # # Attempt to create; ignore if exists\n",
        "# # !bq --location=US mk -d --description \"MGMT467 Netflix dataset\" $DATASET || echo \"Dataset may already exist.\""
      ],
      "id": "IMuyJGutXam1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWnwC6EYXam1"
      },
      "execution_count": 35,
      "outputs": [],
      "source": [
        "# # EXAMPLE (from LLM) — Load tables (commented)\n",
        "# # tables = {\n",
        "# #   \"users\": \"users.csv\",\n",
        "# #   \"movies\": \"movies.csv\",\n",
        "# #   \"watch_history\": \"watch_history.csv\",\n",
        "# #   \"recommendation_logs\": \"recommendation_logs.csv\",\n",
        "# #   \"search_logs\": \"search_logs.csv\",\n",
        "# #   \"reviews\": \"reviews.csv\",\n",
        "# # }\n",
        "# # import os\n",
        "# # for tbl, fname in tables.items():\n",
        "# #   src = f\"gs://{os.environ['BUCKET_NAME']}/netflix/{fname}\"\n",
        "# #   print(\"Loading\", tbl, \"from\", src)\n",
        "# #   !bq load --skip_leading_rows=1 --autodetect --source_format=CSV $DATASET.$tbl $src\n",
        "# #\n",
        "# # # Row counts\n",
        "# # for tbl in tables.keys():\n",
        "# #   !bq query --nouse_legacy_sql \"SELECT '{tbl}' AS table_name, COUNT(*) AS n FROM `${GOOGLE_CLOUD_PROJECT}.netflix.{tbl}`\".format(tbl=tbl)"
      ],
      "id": "ZWnwC6EYXam1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8CnrvkZXam1"
      },
      "source": [
        "### Verification Prompt\n",
        "Generate a single query that returns `table_name, row_count` for all six tables in `${GOOGLE_CLOUD_PROJECT}.netflix`.\n"
      ],
      "id": "_8CnrvkZXam1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc7fbb66",
        "outputId": "132ae9d5-2fbd-4cdb-9e02-376c35136065"
      },
      "source": [
        "# Generate a single query that returns table_name, row_count for all six tables\n",
        "import os\n",
        "project_id = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
        "dataset = \"netflix\"\n",
        "\n",
        "if not project_id:\n",
        "    print(\"Error: GOOGLE_CLOUD_PROJECT environment variable is not set.\")\n",
        "else:\n",
        "    query = f\"\"\"\n",
        "    SELECT 'users' AS table_name, COUNT(*) AS row_count FROM `{project_id}.{dataset}.users`\n",
        "    UNION ALL\n",
        "    SELECT 'movies' AS table_name, COUNT(*) AS row_count FROM `{project_id}.{dataset}.movies`\n",
        "    UNION ALL\n",
        "    SELECT 'watch_history' AS table_name, COUNT(*) AS row_count FROM `{project_id}.{dataset}.watch_history`\n",
        "    UNION ALL\n",
        "    SELECT 'recommendation_logs' AS table_name, COUNT(*) AS row_count FROM `{project_id}.{dataset}.recommendation_logs`\n",
        "    UNION ALL\n",
        "    SELECT 'search_logs' AS table_name, COUNT(*) AS row_count FROM `{project_id}.{dataset}.search_logs`\n",
        "    UNION ALL\n",
        "    SELECT 'reviews' AS table_name, COUNT(*) AS row_count FROM `{project_id}.{dataset}.reviews`\n",
        "    \"\"\"\n",
        "    print(\"Running combined row count query:\")\n",
        "    # Pass the entire query as a single string to the shell command\n",
        "    !bq query --nouse_legacy_sql '''{query}'''"
      ],
      "id": "cc7fbb66",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running combined row count query:\n",
            "Error in query string: Error processing job 'heroic-\n",
            "trilogy-471119-k8:bqjob_r6838a4ed7a0f2e50_0000019a04f9cf82_1': Unrecognized\n",
            "name: users; Did you mean user_id? at [2:12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** I don't know why this does not return the table name and row_count for all 6 tables. Gemini re-generated its codes several times, yet no progress."
      ],
      "metadata": {
        "id": "hxS1V5VqAI-K"
      },
      "id": "hxS1V5VqAI-K"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgjKPzmcXam1"
      },
      "source": [
        "**Reflection:** When is `autodetect` acceptable? When should you enforce explicit schemas and why?\n",
        "\n",
        "'Autodetect' is acceptable during initial exploration and quick loading, consistent and simple data, prototyping and development. Explicit schemas should be enforced during production pipelines, complex or inconsistent data, data validation and governance, performance and cost and while maintaining data type integrity. Furthermore, Enforcing explicit schemas provides control, predictability, and data integrity. It is a critical part of building robust and reliable data pipelines."
      ],
      "id": "vgjKPzmcXam1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytZghVhKXam1"
      },
      "source": [
        "## 5) Data Quality (DQ) — Concepts we care about\n",
        "- **Missingness** (MCAR/MAR/MNAR). Impute vs drop. Add `is_missing_*` indicators.\n",
        "- **Duplicates** (exact vs near). Double-counted engagement corrupts labels & KPIs.\n",
        "- **Outliers** (IQR). Winsorize/cap vs robust models. Always **flag** and explain.\n",
        "- **Reproducibility**. Prefer `CREATE OR REPLACE` and deterministic keys.\n"
      ],
      "id": "ytZghVhKXam1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9_Xfb3rXam2"
      },
      "source": [
        "### 5.1 Missingness (users) — What & Why\n",
        "Measure % missing and check if missingness depends on another variable (MAR) → potential bias & instability."
      ],
      "id": "r9_Xfb3rXam2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C8P5LcVXam2"
      },
      "source": [
        "### Build Prompt\n",
        "Generate **two BigQuery SQL cells**:\n",
        "1) Total rows and % missing in `region`, `plan_tier`, `age_band` from `users`.\n",
        "2) `% plan_tier missing by region` ordered descending. Add comments on MAR.\n"
      ],
      "id": "4C8P5LcVXam2"
    },
    {
      "cell_type": "code",
      "source": [
        "# EXAMPLE (from LLM) — Missingness profile (commented)\n",
        "import os\n",
        "from google.cloud import bigquery\n",
        "\n",
        "project_id = os.environ['GOOGLE_CLOUD_PROJECT']\n",
        "\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "query = f\"\"\"\n",
        "-- Users: % missing per column\n",
        "WITH base AS (\n",
        "  SELECT COUNT(*) n,\n",
        "         COUNTIF(country IS NULL) miss_country,\n",
        "         COUNTIF(subscription_plan IS NULL) miss_plan,\n",
        "         COUNTIF(age IS NULL) miss_age\n",
        "  FROM `{project_id}.netflix.users`\n",
        ")\n",
        "SELECT n,\n",
        "       ROUND(100*miss_country/n,2) AS pct_missing_country,\n",
        "       ROUND(100*miss_plan/n,2)   AS pct_missing_subscription_plan,\n",
        "       ROUND(100*miss_age/n,2)    AS pct_missing_age\n",
        "FROM base;\n",
        "\"\"\"\n",
        "\n",
        "query_job = client.query(query)\n",
        "results = query_job.result()\n",
        "\n",
        "# Print the results\n",
        "for row in results:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gIKqdvgCSlh",
        "outputId": "22e344cd-e0e8-4414-a949-a8ff18928251"
      },
      "id": "0gIKqdvgCSlh",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row((10300, 0.0, 0.0, 11.93), {'n': 0, 'pct_missing_country': 1, 'pct_missing_subscription_plan': 2, 'pct_missing_age': 3})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "dade5d89",
        "outputId": "8112573c-347f-447a-ce94-77956964f28c"
      },
      "source": [
        "# Calculate % subscription_plan missing by country ordered descending\n",
        "# This query calculates the percentage of missing 'subscription_plan' values for each country.\n",
        "# It helps identify if missingness is related to the country (Missing At Random - MAR),\n",
        "# which could introduce bias if not handled appropriately.\n",
        "import os\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "project_id = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
        "\n",
        "if not project_id:\n",
        "    print(\"Error: GOOGLE_CLOUD_PROJECT environment variable is not set.\")\n",
        "else:\n",
        "    query = f\"\"\"\n",
        "    SELECT country,\n",
        "           COUNT(*) AS n,\n",
        "           ROUND(100*COUNTIF(subscription_plan IS NULL)/COUNT(*),2) AS pct_missing_subscription_plan\n",
        "    FROM `{project_id}.netflix.users`\n",
        "    GROUP BY country\n",
        "    ORDER BY pct_missing_subscription_plan DESC;\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Running query for % subscription_plan missing by country:\")\n",
        "    # Execute the query using bq command and capture output\n",
        "    bq_output = !bq query --nouse_legacy_sql --format=csv '{query}'\n",
        "\n",
        "    # The first line of bq_output is the header, subsequent lines are data\n",
        "    # Handle potential empty results or errors\n",
        "    if len(bq_output) > 1:\n",
        "        # Create a pandas DataFrame from the CSV output\n",
        "        csv_data = StringIO(\"\\n\".join(bq_output))\n",
        "        missing_plan_by_country_df = pd.read_csv(csv_data)\n",
        "\n",
        "        # Display the results\n",
        "        display(missing_plan_by_country_df)\n",
        "    else:\n",
        "        print(\"Query returned no results or an error.\")\n",
        "        print(\"\\n\".join(bq_output)) # Print output for debugging if needed"
      ],
      "id": "dade5d89",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running query for % subscription_plan missing by country:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  country     n  pct_missing_subscription_plan\n",
              "0  Canada  3096                            0.0\n",
              "1     USA  7204                            0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f94cbb16-9741-4e55-88a6-cb8dda4f7df8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "      <th>n</th>\n",
              "      <th>pct_missing_subscription_plan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Canada</td>\n",
              "      <td>3096</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>USA</td>\n",
              "      <td>7204</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f94cbb16-9741-4e55-88a6-cb8dda4f7df8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f94cbb16-9741-4e55-88a6-cb8dda4f7df8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f94cbb16-9741-4e55-88a6-cb8dda4f7df8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4ddc8365-a72f-4270-bb81-39a2bc9f610c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4ddc8365-a72f-4270-bb81-39a2bc9f610c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4ddc8365-a72f-4270-bb81-39a2bc9f610c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_99c8af83-59f9-44b9-8209-e80da58d2e62\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('missing_plan_by_country_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_99c8af83-59f9-44b9-8209-e80da58d2e62 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('missing_plan_by_country_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "missing_plan_by_country_df",
              "summary": "{\n  \"name\": \"missing_plan_by_country_df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"country\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"USA\",\n          \"Canada\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2904,\n        \"min\": 3096,\n        \"max\": 7204,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          7204,\n          3096\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pct_missing_subscription_plan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpdR_vciXam2"
      },
      "execution_count": 57,
      "outputs": [],
      "source": [
        "# # EXAMPLE (from LLM) — Missingness profile (commented)\n",
        "# # -- Users: % missing per column\n",
        "# # WITH base AS (\n",
        "# #   SELECT COUNT(*) n,\n",
        "# #          COUNTIF(region IS NULL) miss_region,\n",
        "# #          COUNTIF(plan_tier IS NULL) miss_plan,\n",
        "# #          COUNTIF(age_band IS NULL) miss_age\n",
        "# #   FROM `${GOOGLE_CLOUD_PROJECT}.netflix.users`\n",
        "# # )\n",
        "# # SELECT n,\n",
        "# #        ROUND(100*miss_region/n,2) AS pct_missing_region,\n",
        "# #        ROUND(100*miss_plan/n,2)   AS pct_missing_plan_tier,\n",
        "# #        ROUND(100*miss_age/n,2)    AS pct_missing_age_band\n",
        "# # FROM base;"
      ],
      "id": "NpdR_vciXam2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFhw2wnZXam2"
      },
      "execution_count": 58,
      "outputs": [],
      "source": [
        "# # EXAMPLE (from LLM) — MAR by region (commented)\n",
        "# # SELECT region,\n",
        "# #        COUNT(*) AS n,\n",
        "# #        ROUND(100*COUNTIF(plan_tier IS NULL)/COUNT(*),2) AS pct_missing_plan_tier\n",
        "# # FROM `${GOOGLE_CLOUD_PROJECT}.netflix.users`\n",
        "# # GROUP BY region\n",
        "# # ORDER BY pct_missing_plan_tier DESC;"
      ],
      "id": "KFhw2wnZXam2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3q9Qyz_Xam2"
      },
      "source": [
        "### Verification Prompt\n",
        "Generate a query that prints the three missingness percentages from (1), rounded to two decimals.\n"
      ],
      "id": "b3q9Qyz_Xam2"
    },
    {
      "cell_type": "code",
      "source": [
        "# # EXAMPLE (from LLM) — MAR by region (commented)\n",
        "import os\n",
        "from google.cloud import bigquery\n",
        "\n",
        "project_id = os.environ['GOOGLE_CLOUD_PROJECT']\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "query = f\"\"\"\n",
        "SELECT country,\n",
        "       COUNT(*) AS n,\n",
        "       ROUND(100*COUNTIF(subscription_plan IS NULL)/COUNT(*),2) AS pct_missing_subscription_plan\n",
        "FROM `{project_id}.netflix.users`\n",
        "GROUP BY country\n",
        "ORDER BY pct_missing_subscription_plan DESC;\n",
        "\"\"\"\n",
        "\n",
        "query_job = client.query(query)\n",
        "results = query_job.result()\n",
        "\n",
        "# Print the results\n",
        "for row in results:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJWO3YnAGnHd",
        "outputId": "4ee62041-fd32-4eaa-aef6-e802d84b2761"
      },
      "id": "bJWO3YnAGnHd",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(('Canada', 3096, 0.0), {'country': 0, 'n': 1, 'pct_missing_subscription_plan': 2})\n",
            "Row(('USA', 7204, 0.0), {'country': 0, 'n': 1, 'pct_missing_subscription_plan': 2})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRG_9FghXam2"
      },
      "source": [
        "**Reflection:** Which columns are most missing? Hypothesize MCAR/MAR/MNAR and why.\n",
        "\n",
        "None of the columns have the most missing values. This is because:\n",
        "\n",
        "1. MCAR (Missing Completely At Random): It's possible that the missingness in age_band is completely random and not related to any other variable in the dataset.\n",
        "2. MAR (Missing At Random): The missingness might be related to other observable variables.\n",
        "3. MNAR (Missing Not At Random): The missingness could be related to the age itself."
      ],
      "id": "pRG_9FghXam2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imS_l_gJXam2"
      },
      "source": [
        "### 5.2 Duplicates (watch_history) — What & Why\n",
        "Find exact duplicate interaction records and keep **one best** per group (deterministic policy)."
      ],
      "id": "imS_l_gJXam2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFi2wXxaXam2"
      },
      "source": [
        "### Build Prompt\n",
        "Generate **two BigQuery SQL cells**:\n",
        "1) Report duplicate groups on `(user_id, movie_id, event_ts, device_type)` with counts (top 20).\n",
        "2) Create table `watch_history_dedup` that keeps one row per group (prefer higher `progress_ratio`, then `minutes_watched`). Add comments.\n"
      ],
      "id": "MFi2wXxaXam2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M68-KOhXam2"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# # EXAMPLE (from LLM) — Detect duplicate groups (commented)\n",
        "# # SELECT user_id, movie_id, event_ts, device_type, COUNT(*) AS dup_count\n",
        "# # FROM `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history`\n",
        "# # GROUP BY user_id, movie_id, event_ts, device_type\n",
        "# # HAVING dup_count > 1\n",
        "# # ORDER BY dup_count DESC\n",
        "# # LIMIT 20;"
      ],
      "id": "8M68-KOhXam2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "eef6ec5f",
        "outputId": "66d79425-18ac-4f4e-b049-1f757dbeb0cb"
      },
      "source": [
        "# Report duplicate groups with counts (top 20) and display in a DataFrame\n",
        "# Using the correct event timestamp column: watch_date\n",
        "import os\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "project_id = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
        "if not project_id:\n",
        "    print(\"Error: GOOGLE_CLOUD_PROJECT environment variable is not set.\")\n",
        "else:\n",
        "    # Correct column name identified from schema\n",
        "    event_timestamp_column = 'watch_date'\n",
        "\n",
        "    query = f\"\"\"\n",
        "    SELECT user_id, movie_id, {event_timestamp_column}, device_type, COUNT(*) AS dup_count\n",
        "    FROM `{project_id}.netflix.watch_history`\n",
        "    GROUP BY user_id, movie_id, {event_timestamp_column}, device_type\n",
        "    HAVING dup_count > 1\n",
        "    ORDER BY dup_count DESC\n",
        "    LIMIT 20;\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Running query to report duplicate groups (using {event_timestamp_column}):\")\n",
        "    # Execute the query using bq command and capture output in CSV format\n",
        "    bq_output = !bq query --nouse_legacy_sql --format=csv '{query}'\n",
        "\n",
        "    # Handle potential empty results or errors\n",
        "    if len(bq_output) > 1:\n",
        "        # Create a pandas DataFrame from the CSV output\n",
        "        csv_data = StringIO(\"\\n\".join(bq_output))\n",
        "        duplicate_groups_df = pd.read_csv(csv_data)\n",
        "\n",
        "        # Display the results\n",
        "        display(duplicate_groups_df)\n",
        "    else:\n",
        "        print(\"Query returned no results or an error.\")\n",
        "        print(\"\\n\".join(bq_output)) # Print output for debugging if needed"
      ],
      "id": "eef6ec5f",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running query to report duplicate groups (using watch_date):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       user_id    movie_id  watch_date device_type  dup_count\n",
              "0   user_03310  movie_0640  2024-09-08    Smart TV          4\n",
              "1   user_00391  movie_0893  2024-08-26      Laptop          4\n",
              "2   user_07617  movie_0785  2024-07-14     Desktop          3\n",
              "3   user_05629  movie_0697  2025-01-23     Desktop          3\n",
              "4   user_06799  movie_0458  2024-08-15     Desktop          3\n",
              "5   user_04899  movie_0142  2025-01-20     Desktop          3\n",
              "6   user_02652  movie_0352  2024-10-22     Desktop          3\n",
              "7   user_02126  movie_0642  2025-02-09     Desktop          3\n",
              "8   user_01581  movie_0933  2024-03-30     Desktop          3\n",
              "9   user_05952  movie_0893  2024-04-29     Desktop          3\n",
              "10  user_08276  movie_0460  2024-04-24     Desktop          3\n",
              "11  user_06295  movie_0097  2025-02-24     Desktop          3\n",
              "12  user_09973  movie_0342  2025-03-22     Desktop          3\n",
              "13  user_02976  movie_0987  2024-09-19     Desktop          3\n",
              "14  user_05811  movie_0177  2024-05-07     Desktop          3\n",
              "15  user_08826  movie_0133  2025-04-11     Desktop          3\n",
              "16  user_00965  movie_0991  2024-02-14     Desktop          3\n",
              "17  user_02028  movie_0037  2024-08-13     Desktop          3\n",
              "18  user_09512  movie_0825  2025-01-07     Desktop          3\n",
              "19  user_02359  movie_0108  2024-10-12     Desktop          3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d389d9fd-7afc-4f0e-a66f-f13bd349ab6d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>movie_id</th>\n",
              "      <th>watch_date</th>\n",
              "      <th>device_type</th>\n",
              "      <th>dup_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>user_03310</td>\n",
              "      <td>movie_0640</td>\n",
              "      <td>2024-09-08</td>\n",
              "      <td>Smart TV</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>user_00391</td>\n",
              "      <td>movie_0893</td>\n",
              "      <td>2024-08-26</td>\n",
              "      <td>Laptop</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>user_07617</td>\n",
              "      <td>movie_0785</td>\n",
              "      <td>2024-07-14</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>user_05629</td>\n",
              "      <td>movie_0697</td>\n",
              "      <td>2025-01-23</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>user_06799</td>\n",
              "      <td>movie_0458</td>\n",
              "      <td>2024-08-15</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>user_04899</td>\n",
              "      <td>movie_0142</td>\n",
              "      <td>2025-01-20</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>user_02652</td>\n",
              "      <td>movie_0352</td>\n",
              "      <td>2024-10-22</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>user_02126</td>\n",
              "      <td>movie_0642</td>\n",
              "      <td>2025-02-09</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>user_01581</td>\n",
              "      <td>movie_0933</td>\n",
              "      <td>2024-03-30</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>user_05952</td>\n",
              "      <td>movie_0893</td>\n",
              "      <td>2024-04-29</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>user_08276</td>\n",
              "      <td>movie_0460</td>\n",
              "      <td>2024-04-24</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>user_06295</td>\n",
              "      <td>movie_0097</td>\n",
              "      <td>2025-02-24</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>user_09973</td>\n",
              "      <td>movie_0342</td>\n",
              "      <td>2025-03-22</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>user_02976</td>\n",
              "      <td>movie_0987</td>\n",
              "      <td>2024-09-19</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>user_05811</td>\n",
              "      <td>movie_0177</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>user_08826</td>\n",
              "      <td>movie_0133</td>\n",
              "      <td>2025-04-11</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>user_00965</td>\n",
              "      <td>movie_0991</td>\n",
              "      <td>2024-02-14</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>user_02028</td>\n",
              "      <td>movie_0037</td>\n",
              "      <td>2024-08-13</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>user_09512</td>\n",
              "      <td>movie_0825</td>\n",
              "      <td>2025-01-07</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>user_02359</td>\n",
              "      <td>movie_0108</td>\n",
              "      <td>2024-10-12</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d389d9fd-7afc-4f0e-a66f-f13bd349ab6d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d389d9fd-7afc-4f0e-a66f-f13bd349ab6d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d389d9fd-7afc-4f0e-a66f-f13bd349ab6d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f5fb26be-8a87-4699-a0f7-40881dde9238\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f5fb26be-8a87-4699-a0f7-40881dde9238')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f5fb26be-8a87-4699-a0f7-40881dde9238 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_74701c73-2cc4-4449-a15a-f85346b450b1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('duplicate_groups_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_74701c73-2cc4-4449-a15a-f85346b450b1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('duplicate_groups_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "duplicate_groups_df",
              "summary": "{\n  \"name\": \"duplicate_groups_df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"user_03310\",\n          \"user_02028\",\n          \"user_08826\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"movie_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"movie_0640\",\n          \"movie_0142\",\n          \"movie_0342\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"watch_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"2024-09-08\",\n          \"2024-08-13\",\n          \"2025-04-11\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"device_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Smart TV\",\n          \"Laptop\",\n          \"Desktop\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dup_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.cloud import bigquery\n",
        "\n",
        "project_id = os.environ['GOOGLE_CLOUD_PROJECT']\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "query = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{project_id}.netflix.watch_history_dedup` AS\n",
        "SELECT * EXCEPT(rk) FROM (\n",
        "  SELECT h.*,\n",
        "         ROW_NUMBER() OVER (\n",
        "           PARTITION BY user_id, movie_id, watch_date, device_type\n",
        "           ORDER BY progress_percentage DESC, watch_duration_minutes DESC\n",
        "         ) AS rk\n",
        "  FROM `{project_id}.netflix.watch_history` h\n",
        ")\n",
        "WHERE rk = 1;\n",
        "\"\"\"\n",
        "\n",
        "query_job = client.query(query)\n",
        "results = query_job.result()\n",
        "\n",
        "print(\"Deduplicated table watch_history_dedup created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvA1hftZMh_s",
        "outputId": "0bcdd41e-fc9c-4b25-bb1d-092fa9b7cd0f"
      },
      "id": "RvA1hftZMh_s",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deduplicated table watch_history_dedup created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4e6debb",
        "outputId": "e3f77478-3a0d-4297-9d4b-f17b877333b9"
      },
      "source": [
        "# Create table watch_history_dedup that keeps one row per group\n",
        "# Using the correct event timestamp column: watch_date\n",
        "# This query creates a new table with duplicate interaction records removed.\n",
        "# It uses a window function to assign a rank within each duplicate group,\n",
        "# prioritizing rows with a higher progress_ratio and then minutes_watched,\n",
        "# and keeps only the top-ranked row (rk = 1).\n",
        "import os\n",
        "project_id = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
        "if not project_id:\n",
        "    print(\"Error: GOOGLE_CLOUD_PROJECT environment variable is not set.\")\n",
        "else:\n",
        "    # Correct column name identified from schema\n",
        "    event_timestamp_column = 'watch_date'\n",
        "    # Correct column name for minutes watched identified from schema\n",
        "    minutes_watched_column = 'watch_duration_minutes'\n",
        "    # Correct column name for progress ratio identified from schema\n",
        "    progress_ratio_column = 'progress_percentage'\n",
        "\n",
        "\n",
        "    query = f\"\"\"\n",
        "    CREATE OR REPLACE TABLE `{project_id}.netflix.watch_history_dedup` AS\n",
        "    SELECT * EXCEPT(rk) FROM (\n",
        "      SELECT h.*,\n",
        "             ROW_NUMBER() OVER (\n",
        "               PARTITION BY user_id, movie_id, {event_timestamp_column}, device_type\n",
        "               ORDER BY {progress_ratio_column} DESC, {minutes_watched_column} DESC\n",
        "             ) AS rk\n",
        "      FROM `{project_id}.netflix.watch_history` h\n",
        "    )\n",
        "    WHERE rk = 1;\n",
        "    \"\"\"\n",
        "    print(\"Running query to create watch_history_dedup table:\")\n",
        "    !bq query --nouse_legacy_sql '{query}'"
      ],
      "id": "a4e6debb",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running query to create watch_history_dedup table:\n",
            "Waiting on bqjob_r543700651c899001_0000019a052cc90c_1 ... (1s) Current status: DONE   \n",
            "Created heroic-trilogy-471119-k8.netflix.watch_history_dedup\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbMOra8iXam7"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# # EXAMPLE (from LLM) — Keep-one policy (commented)\n",
        "# # CREATE OR REPLACE TABLE `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history_dedup` AS\n",
        "# # SELECT * EXCEPT(rk) FROM (\n",
        "# #   SELECT h.*,\n",
        "# #          ROW_NUMBER() OVER (\n",
        "# #            PARTITION BY user_id, movie_id, event_ts, device_type\n",
        "# #            ORDER BY progress_ratio DESC, minutes_watched DESC\n",
        "# #          ) AS rk\n",
        "# #   FROM `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history` h\n",
        "# # )\n",
        "# # WHERE rk = 1;"
      ],
      "id": "CbMOra8iXam7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both my verification codes came from the sample document uploaded by the professor on GitHub. I tried creating the prompts myself and got a generated code. However, there were resulting in error despite mutiple fixes."
      ],
      "metadata": {
        "id": "y4u1CC7xNK2w"
      },
      "id": "y4u1CC7xNK2w"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeIgAeTAXam8"
      },
      "source": [
        "### Verification Prompt\n",
        "Generate a before/after count query comparing raw vs `watch_history_dedup`.\n"
      ],
      "id": "OeIgAeTAXam8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "998cde3e",
        "outputId": "7e0d4a30-aba8-4be2-febb-828ab6e3d77a"
      },
      "source": [
        "# Generate a before/after count query comparing raw vs watch_history_dedup\n",
        "import os\n",
        "from google.cloud import bigquery\n",
        "\n",
        "project_id = os.environ['GOOGLE_CLOUD_PROJECT']\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "query = f\"\"\"\n",
        "SELECT 'raw' AS table_name, COUNT(*) AS row_count FROM `{project_id}.netflix.watch_history`\n",
        "UNION ALL\n",
        "SELECT 'deduplicated' AS table_name, COUNT(*) AS row_count FROM `{project_id}.netflix.watch_history_dedup`;\n",
        "\"\"\"\n",
        "\n",
        "query_job = client.query(query)\n",
        "results = query_job.result()\n",
        "\n",
        "# Print the results\n",
        "for row in results:\n",
        "    print(row)"
      ],
      "id": "998cde3e",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(('raw', 105000), {'table_name': 0, 'row_count': 1})\n",
            "Row(('deduplicated', 100000), {'table_name': 0, 'row_count': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soYeqhMwXam8"
      },
      "source": [
        "**Reflection:** Why do duplicates arise (natural vs system-generated)? How do they corrupt labels and KPIs?\n",
        "\n",
        "Duplicates in data can stem from various sources, including operational errors like multiple data entry points or system issues such as retry mechanisms in data pipelines. These duplicates are problematic because they inflate counts and skew aggregations, leading to inaccurate Key Performance Indicators (KPIs). For machine learning, duplicated data can cause models to overfit and learn biased relationships, ultimately corrupting labels and resulting in unreliable predictions and misleading business insights."
      ],
      "id": "soYeqhMwXam8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIOc3LtHXam8"
      },
      "source": [
        "### 5.3 Outliers (minutes_watched) — What & Why\n",
        "Estimate extreme values via IQR; report % outliers; **winsorize** to P01/P99 for robustness while also **flagging** extremes."
      ],
      "id": "SIOc3LtHXam8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU2bYtPyXam8"
      },
      "source": [
        "### Build Prompt\n",
        "Generate **two BigQuery SQL cells**:\n",
        "1) Compute IQR bounds for `minutes_watched` on `watch_history_dedup` and report % outliers.\n",
        "2) Create `watch_history_robust` with `minutes_watched_capped` capped at P01/P99; return quantile summaries before/after.\n"
      ],
      "id": "kU2bYtPyXam8"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.cloud import bigquery\n",
        "\n",
        "project_id = os.environ['GOOGLE_CLOUD_PROJECT']\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "query = f\"\"\"\n",
        "WITH dist AS (\n",
        "  SELECT\n",
        "    APPROX_QUANTILES(watch_duration_minutes, 4)[OFFSET(1)] AS q1,\n",
        "    APPROX_QUANTILES(watch_duration_minutes, 4)[OFFSET(3)] AS q3\n",
        "  FROM `{project_id}.netflix.watch_history_dedup`\n",
        "),\n",
        "bounds AS (\n",
        "  SELECT q1, q3, (q3-q1) AS iqr,\n",
        "         q1 - 1.5*(q3-q1) AS lo,\n",
        "         q3 + 1.5*(q3-q1) AS hi\n",
        "  FROM dist\n",
        ")\n",
        "SELECT\n",
        "  COUNTIF(h.watch_duration_minutes < b.lo OR h.watch_duration_minutes > b.hi) AS outliers,\n",
        "  COUNT(*) AS total,\n",
        "  ROUND(100*COUNTIF(h.watch_duration_minutes < b.lo OR h.watch_duration_minutes > b.hi)/COUNT(*),2) AS pct_outliers\n",
        "FROM `{project_id}.netflix.watch_history_dedup` h\n",
        "CROSS JOIN bounds b;\n",
        "\"\"\"\n",
        "\n",
        "query_job = client.query(query)\n",
        "results = query_job.result()\n",
        "\n",
        "# Print the results\n",
        "for row in results:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z0RQ0l1PS1h",
        "outputId": "ef81c5bf-f916-4dfb-e351-db5147c1b47d"
      },
      "id": "3z0RQ0l1PS1h",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row((3439, 100000, 3.44), {'outliers': 0, 'total': 1, 'pct_outliers': 2})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4oRbN4WXam8"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# # EXAMPLE (from LLM) — IQR outlier rate (commented)\n",
        "# # WITH dist AS (\n",
        "# #   SELECT\n",
        "# #     APPROX_QUANTILES(minutes_watched, 4)[OFFSET(1)] AS q1,\n",
        "# #     APPROX_QUANTILES(minutes_watched, 4)[OFFSET(3)] AS q3\n",
        "# #   FROM `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history_dedup`\n",
        "# # ),\n",
        "# # bounds AS (\n",
        "# #   SELECT q1, q3, (q3-q1) AS iqr,\n",
        "# #          q1 - 1.5*(q3-q1) AS lo,\n",
        "# #          q3 + 1.5*(q3-q1) AS hi\n",
        "# #   FROM dist\n",
        "# # )\n",
        "# # SELECT\n",
        "# #   COUNTIF(h.minutes_watched < b.lo OR h.minutes_watched > b.hi) AS outliers,\n",
        "# #   COUNT(*) AS total,\n",
        "# #   ROUND(100*COUNTIF(h.minutes_watched < b.lo OR h.minutes_watched > b.hi)/COUNT(*),2) AS pct_outliers\n",
        "# # FROM `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history_dedup` h\n",
        "# # CROSS JOIN bounds b;"
      ],
      "id": "m4oRbN4WXam8"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.cloud import bigquery\n",
        "\n",
        "project_id = os.environ['GOOGLE_CLOUD_PROJECT']\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "query = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{project_id}.netflix.watch_history_robust` AS\n",
        "WITH q AS (\n",
        "  SELECT\n",
        "    APPROX_QUANTILES(watch_duration_minutes, 100)[OFFSET(1)]  AS p01,\n",
        "    APPROX_QUANTILES(watch_duration_minutes, 100)[OFFSET(98)] AS p99\n",
        "  FROM `{project_id}.netflix.watch_history_dedup`\n",
        ")\n",
        "SELECT\n",
        "  h.*,\n",
        "  GREATEST(q.p01, LEAST(q.p99, h.watch_duration_minutes)) AS watch_duration_minutes_capped\n",
        "FROM `{project_id}.netflix.watch_history_dedup` h, q;\n",
        "\n",
        "-- Quantiles before vs after\n",
        "WITH before AS (\n",
        "  SELECT 'before' AS which, APPROX_QUANTILES(watch_duration_minutes, 5) AS q\n",
        "  FROM `{project_id}.netflix.watch_history_dedup`\n",
        "),\n",
        "after AS (\n",
        "  SELECT 'after' AS which, APPROX_QUANTILES(watch_duration_minutes_capped, 5) AS q\n",
        "  FROM `{project_id}.netflix.watch_history_robust`\n",
        ")\n",
        "SELECT * FROM before UNION ALL SELECT * FROM after;\n",
        "\"\"\"\n",
        "\n",
        "query_job = client.query(query)\n",
        "results = query_job.result()\n",
        "\n",
        "# Print the results\n",
        "for row in results:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpRDZu-2PUDg",
        "outputId": "e5c3efcc-5df1-484b-8894-a494c5ca44d4"
      },
      "id": "XpRDZu-2PUDg",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(('before', [0.2, 24.9, 41.8, 61.4, 92.0, 799.3]), {'which': 0, 'q': 1})\n",
            "Row(('after', [4.4, 24.6, 41.5, 61.5, 92.0, 204.0]), {'which': 0, 'q': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4ATpACvXam8"
      },
      "execution_count": 83,
      "outputs": [],
      "source": [
        "# # EXAMPLE (from LLM) — Winsorize + quantiles (commented)\n",
        "# # CREATE OR REPLACE TABLE `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history_robust` AS\n",
        "# # WITH q AS (\n",
        "# #   SELECT\n",
        "# #     APPROX_QUANTILES(minutes_watched, 100)[OFFSET(1)]  AS p01,\n",
        "# #     APPROX_QUANTILES(minutes_watched, 100)[OFFSET(98)] AS p99\n",
        "# #   FROM `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history_dedup`\n",
        "# # )\n",
        "# # SELECT\n",
        "# #   h.*,\n",
        "# #   GREATEST(q.p01, LEAST(q.p99, h.minutes_watched)) AS minutes_watched_capped\n",
        "# # FROM `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history_dedup` h, q;\n",
        "# #\n",
        "# # -- Quantiles before vs after\n",
        "# # WITH before AS (\n",
        "# #   SELECT 'before' AS which, APPROX_QUANTILES(minutes_watched, 5) AS q\n",
        "# #   FROM `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history_dedup`\n",
        "# # ),\n",
        "# # after AS (\n",
        "# #   SELECT 'after' AS which, APPROX_QUANTILES(minutes_watched_capped, 5) AS q\n",
        "# #   FROM `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history_robust`\n",
        "# # )\n",
        "# # SELECT * FROM before UNION ALL SELECT * FROM after;"
      ],
      "id": "V4ATpACvXam8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both my codes came from the sample document uploaded by the professor on GitHub. I tried creating the prompts myself and got a generated code. However, there were resulting in error despite mutiple fixes."
      ],
      "metadata": {
        "id": "nDraIiGjQgRb"
      },
      "id": "nDraIiGjQgRb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSMBxUelXam8"
      },
      "source": [
        "### Verification Prompt\n",
        "Generate a query that shows min/median/max before vs after capping.\n"
      ],
      "id": "JSMBxUelXam8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Verification: Show min/median/max before vs after capping\n",
        "import os\n",
        "from google.cloud import bigquery\n",
        "\n",
        "project_id = os.environ['GOOGLE_CLOUD_PROJECT']\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "query = f\"\"\"\n",
        "WITH before AS (\n",
        "  SELECT\n",
        "    'before' AS which,\n",
        "    MIN(watch_duration_minutes) AS min_val,\n",
        "    APPROX_QUANTILES(watch_duration_minutes, 2)[OFFSET(1)] AS median_val,\n",
        "    MAX(watch_duration_minutes) AS max_val\n",
        "  FROM `{project_id}.netflix.watch_history_dedup`\n",
        "),\n",
        "after AS (\n",
        "  SELECT\n",
        "    'after' AS which,\n",
        "    MIN(watch_duration_minutes_capped) AS min_val,\n",
        "    APPROX_QUANTILES(watch_duration_minutes_capped, 2)[OFFSET(1)] AS median_val,\n",
        "    MAX(watch_duration_minutes_capped) AS max_val\n",
        "  FROM `{project_id}.netflix.watch_history_robust`\n",
        ")\n",
        "SELECT * FROM before UNION ALL SELECT * FROM after;\n",
        "\"\"\"\n",
        "\n",
        "query_job = client.query(query)\n",
        "results = query_job.result()\n",
        "\n",
        "# Print the results\n",
        "for row in results:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YnipV1CQtOB",
        "outputId": "d323ca2a-709b-40e3-901d-40ed16219cc1"
      },
      "id": "0YnipV1CQtOB",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(('after', 4.4, 51.4, 204.0), {'which': 0, 'min_val': 1, 'median_val': 2, 'max_val': 3})\n",
            "Row(('before', 0.2, 51.0, 799.3), {'which': 0, 'min_val': 1, 'median_val': 2, 'max_val': 3})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7oYFn6zXam8"
      },
      "source": [
        "**Reflection:** When might capping be harmful? Name a model type less sensitive to outliers and why.\n",
        "\n",
        "Capping outliers can be harmful if the extreme values represent genuine, important information rather than errors, potentially distorting the data's true distribution and reducing interpretability. Tree-based models such as Decision Trees, Random Forests, and Gradient Boosting Machines are generally less sensitive to outliers because they make decisions based on splitting data at thresholds rather than relying on the exact magnitude of values or assuming linear relationships, making them more robust to extreme points."
      ],
      "id": "-7oYFn6zXam8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoZ-meltXam8"
      },
      "source": [
        "### 5.4 Business anomaly flags — What & Why\n",
        "Human-readable flags help both product decisioning and ML features (e.g., binge behavior)."
      ],
      "id": "IoZ-meltXam8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Isa5MJseXam8"
      },
      "source": [
        "### Build Prompt\n",
        "Generate **three BigQuery SQL cells** (adjust if columns differ):\n",
        "1) In `watch_history_robust`, compute and summarize `flag_binge` for sessions > 8 hours.\n",
        "2) In `users`, compute and summarize `flag_age_extreme` if age can be parsed from `age_band` (<10 or >100).\n",
        "3) In `movies`, compute and summarize `flag_duration_anomaly` where `duration_min` < 15 or > 480 (if exists).\n",
        "Each cell should output count and percentage and include 1–2 comments.\n"
      ],
      "id": "Isa5MJseXam8"
    },
    {
      "cell_type": "code",
      "source": [
        "# # EXAMPLE (from LLM) — flag_binge\n",
        "import os\n",
        "from google.cloud import bigquery\n",
        "\n",
        "project_id = os.environ['GOOGLE_CLOUD_PROJECT']\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "query = f\"\"\"\n",
        "SELECT\n",
        "  COUNTIF(watch_duration_minutes_capped > 8*60) AS sessions_over_8h,\n",
        "  COUNT(*) AS total,\n",
        "  ROUND(100*COUNTIF(watch_duration_minutes_capped > 8*60)/COUNT(*),2) AS pct\n",
        "FROM `{project_id}.netflix.watch_history_robust`;\n",
        "\"\"\"\n",
        "\n",
        "query_job = client.query(query)\n",
        "results = query_job.result()\n",
        "\n",
        "# Print the results\n",
        "for row in results:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WstlREq0RGyK",
        "outputId": "33a2dbfe-3718-411c-e535-72a7dbcae9c7"
      },
      "id": "WstlREq0RGyK",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row((0, 100000, 0.0), {'sessions_over_8h': 0, 'total': 1, 'pct': 2})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # EXAMPLE (from LLM) — flag_age_extreme (commented)\n",
        "import os\n",
        "from google.cloud import bigquery\n",
        "\n",
        "project_id = os.environ['GOOGLE_CLOUD_PROJECT']\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "query = f\"\"\"\n",
        "SELECT\n",
        "  COUNTIF(age < 10 OR age > 100) AS extreme_age_rows,\n",
        "  COUNT(*) AS total,\n",
        "  ROUND(100*COUNTIF(age < 10 OR age > 100)/COUNT(*),2) AS pct\n",
        "FROM `{project_id}.netflix.users`;\n",
        "\"\"\"\n",
        "\n",
        "query_job = client.query(query)\n",
        "results = query_job.result()\n",
        "\n",
        "# Print the results\n",
        "for row in results:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi-GLfwKRG84",
        "outputId": "cec53a0c-ffe8-40f1-d7ea-94f32153eece"
      },
      "id": "vi-GLfwKRG84",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row((179, 10300, 1.74), {'extreme_age_rows': 0, 'total': 1, 'pct': 2})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # EXAMPLE (from LLM) — flag_duration_anomaly (commented)\n",
        "import os\n",
        "from google.cloud import bigquery\n",
        "\n",
        "project_id = os.environ['GOOGLE_CLOUD_PROJECT']\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "query = f\"\"\"\n",
        "SELECT\n",
        "  COUNTIF(duration_minutes < 15) AS titles_under_15m,\n",
        "  COUNTIF(duration_minutes > 480) AS titles_over_8h,\n",
        "  COUNT(*) AS total,\n",
        "  ROUND(100*COUNTIF(duration_minutes < 15 OR duration_minutes > 480)/COUNT(*),2) AS pct_duration_anomaly\n",
        "FROM `{project_id}.netflix.movies`;\n",
        "\"\"\"\n",
        "\n",
        "query_job = client.query(query)\n",
        "results = query_job.result()\n",
        "\n",
        "# Print the results\n",
        "for row in results:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEd5oazcRHIN",
        "outputId": "d1baa072-c660-429f-841b-1dcd365bb371"
      },
      "id": "aEd5oazcRHIN",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row((12, 11, 1040, 2.21), {'titles_under_15m': 0, 'titles_over_8h': 1, 'total': 2, 'pct_duration_anomaly': 3})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMPZrSJbXam8"
      },
      "execution_count": 88,
      "outputs": [],
      "source": [
        "# # EXAMPLE (from LLM) — flag_binge (commented)\n",
        "# # SELECT\n",
        "# #   COUNTIF(minutes_watched > 8*60) AS sessions_over_8h,\n",
        "# #   COUNT(*) AS total,\n",
        "# #   ROUND(100*COUNTIF(minutes_watched > 8*60)/COUNT(*),2) AS pct\n",
        "# # FROM `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history_robust`;"
      ],
      "id": "AMPZrSJbXam8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLKVd94FXam9"
      },
      "execution_count": 89,
      "outputs": [],
      "source": [
        "# # EXAMPLE (from LLM) — flag_age_extreme (commented)\n",
        "# # SELECT\n",
        "# #   COUNTIF(CAST(REGEXP_EXTRACT(age_band, r'\\d+') AS INT64) < 10 OR\n",
        "# #           CAST(REGEXP_EXTRACT(age_band, r'\\d+') AS INT64) > 100) AS extreme_age_rows,\n",
        "# #   COUNT(*) AS total,\n",
        "# #   ROUND(100*COUNTIF(CAST(REGEXP_EXTRACT(age_band, r'\\d+') AS INT64) < 10 OR\n",
        "# #                     CAST(REGEXP_EXTRACT(age_band, r'\\d+') AS INT64) > 100)/COUNT(*),2) AS pct\n",
        "# # FROM `${GOOGLE_CLOUD_PROJECT}.netflix.users`;"
      ],
      "id": "QLKVd94FXam9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkfF0m4uXam9"
      },
      "execution_count": 90,
      "outputs": [],
      "source": [
        "# # EXAMPLE (from LLM) — flag_duration_anomaly (commented)\n",
        "# # SELECT\n",
        "# #   COUNTIF(duration_min < 15) AS titles_under_15m,\n",
        "# #   COUNTIF(duration_min > 8*60) AS titles_over_8h,\n",
        "# #   COUNT(*) AS total\n",
        "# # FROM `${GOOGLE_CLOUD_PROJECT}.netflix.movies`;"
      ],
      "id": "wkfF0m4uXam9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the commented codes and the sample document uploaded by the professor on GitHub. I tried creating the prompts myself and got a generated code. However, there were resulting in error despite mutiple fixes."
      ],
      "metadata": {
        "id": "KDo6UqeoR1o1"
      },
      "id": "KDo6UqeoR1o1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qwbkeoEXam9"
      },
      "source": [
        "### Verification Prompt\n",
        "Generate a single compact summary query that returns two columns per flag: `flag_name, pct_of_rows`.\n"
      ],
      "id": "3qwbkeoEXam9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c901aa15",
        "outputId": "b7427a21-b88c-42c2-9038-3322bd966100"
      },
      "source": [
        "# Generate a single compact summary query that returns two columns per flag: flag_name, pct_of_rows\n",
        "import os\n",
        "from google.cloud import bigquery\n",
        "\n",
        "project_id = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
        "if not project_id:\n",
        "    print(\"Error: GOOGLE_CLOUD_PROJECT environment variable is not set.\")\n",
        "else:\n",
        "    client = bigquery.Client(project=project_id)\n",
        "\n",
        "    query = f\"\"\"\n",
        "    -- Calculate percentage for flag_binge from watch_history_robust\n",
        "    SELECT 'flag_binge' AS flag_name,\n",
        "           ROUND(100 * COUNTIF(watch_duration_minutes_capped > 8*60) / COUNT(*), 2) AS pct_of_rows\n",
        "    FROM `{project_id}.netflix.watch_history_robust`\n",
        "\n",
        "    UNION ALL\n",
        "\n",
        "    -- Calculate percentage for flag_age_extreme from users\n",
        "    SELECT 'flag_age_extreme' AS flag_name,\n",
        "           ROUND(100 * COUNTIF(age < 10 OR age > 100) / COUNT(*), 2) AS pct_of_rows\n",
        "    FROM `{project_id}.netflix.users`\n",
        "\n",
        "    UNION ALL\n",
        "\n",
        "    -- Calculate percentage for flag_duration_anomaly from movies\n",
        "    SELECT 'flag_duration_anomaly' AS flag_name,\n",
        "           ROUND(100 * COUNTIF(duration_minutes < 15 OR duration_minutes > 480) / COUNT(*), 2) AS pct_of_rows\n",
        "    FROM `{project_id}.netflix.movies`;\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Running summary query for anomaly flags:\")\n",
        "    query_job = client.query(query)\n",
        "    results = query_job.result()\n",
        "\n",
        "    # Print the results\n",
        "    for row in results:\n",
        "        print(row)"
      ],
      "id": "c901aa15",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running summary query for anomaly flags:\n",
            "Row(('flag_binge', 0.0), {'flag_name': 0, 'pct_of_rows': 1})\n",
            "Row(('flag_age_extreme', 1.74), {'flag_name': 0, 'pct_of_rows': 1})\n",
            "Row(('flag_duration_anomaly', 2.21), {'flag_name': 0, 'pct_of_rows': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKGw4QIZXam9"
      },
      "source": [
        "**Reflection:** Which anomaly flag is most common? Which would you keep as a feature and why?\n",
        "\n",
        "The 'flag_duration_anomaly' is the most common. I would keep this anomaly type as a feature because it seems more directly relevant to content-based or interaction-based modeling tasks."
      ],
      "id": "HKGw4QIZXam9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQBV-5A9Xam9"
      },
      "source": [
        "## 6) Save & submit — What & Why\n",
        "Reproducibility: save artifacts and document decisions so others can rerun and audit."
      ],
      "id": "xQBV-5A9Xam9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB2rqCIxXam9"
      },
      "source": [
        "### Build Prompt\n",
        "Generate a checklist (Markdown) students can paste at the end:\n",
        "- Save this notebook to the team Drive.\n",
        "- Export a `.sql` file with your DQ queries and save to repo.\n",
        "- Push notebook + SQL to the **team GitHub** with a descriptive commit.\n",
        "- Add a README with your `PROJECT_ID`, `REGION`, bucket, dataset, and today’s row counts.\n"
      ],
      "id": "rB2rqCIxXam9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfZ6IzSVXam9"
      },
      "source": [
        "## Grading rubric (quick)\n",
        "- Profiling completeness (30)  \n",
        "- Cleaning policy correctness & reproducibility (40)  \n",
        "- Reflection/insight (20)  \n",
        "- Hygiene (naming, verification, idempotence) (10)\n"
      ],
      "id": "GfZ6IzSVXam9"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}